{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThanhTad/Lab_ML/blob/main/Lab_4_20130222_CaoThanhDat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to continous dealing with **Logistic Regression**, **kNN**, and **Decision Tree** alogirthms applied to classification tasks. \n",
        "\n",
        "*   **Deadline: 23:59, 12/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59f6e1a-11f7-4709-8367-602327be4d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/lab4_ml\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/lab4_ml'\n",
        "import pandas as pd \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Apply **LogisticRegression** to iris dataset which aims at classifying species of iris based on sepal_length (chiều dài đài hoa), sepal_width, petal_length (chiều dài cánh hoa), petal_width. The species are '**setosa**' '**versicolor**' and '**virginica**'. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code  \n",
        "data4 = datasets.load_iris()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data4.data, data4.target, test_size = 0.25)\n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"confusion matrix: \\n\", confusion_matrix(Y_test, y_pred))\n",
        "print(\"precision: \", precision_score(Y_test, y_pred, average='micro'))\n",
        "print(\"recall: \", recall_score(Y_test, y_pred, average='micro'))\n",
        "print(\"f1: \", f1_score(Y_test, y_pred, average='micro'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d24a211-4dfa-46ad-8e4a-ef4b990f6ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: \n",
            " [[ 9  0  0]\n",
            " [ 0 16  1]\n",
            " [ 0  0 12]]\n",
            "precision:  0.9736842105263158\n",
            "recall:  0.9736842105263158\n",
            "f1:  0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "Apply LogisticRegression to **MNIST** dataset (mnist.csv) which aims at classifying handwritten digits. Dataset includes 784 pixels values of images (28x28). \n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "# load the MNIST digits dataset\n",
        "mnist = datasets.load_digits()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(mnist.data, mnist.target, test_size = 0.25)\n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"confusion matrix: \\n\", confusion_matrix(Y_test, y_pred))\n",
        "print(\"precision: \", precision_score(Y_test, y_pred, average='micro'))\n",
        "print(\"recall: \", recall_score(Y_test, y_pred, average='micro'))\n",
        "print(\"f1: \", f1_score(Y_test, y_pred, average='micro'))\n"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6c22a2-ee4b-466a-fcd5-cc4c03b70d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix: \n",
            " [[51  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  1  0  0  0  0  1  0]\n",
            " [ 0  0 31  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 49  0  0  0  0  0  1]\n",
            " [ 0  0  0  0 36  0  0  1  0  2]\n",
            " [ 0  0  0  0  0 39  2  1  1  0]\n",
            " [ 0  0  0  0  0  0 42  0  0  0]\n",
            " [ 0  0  0  0  1  0  0 47  0  0]\n",
            " [ 0  5  0  0  0  0  0  0 41  0]\n",
            " [ 0  0  0  0  0  0  0  1  1 55]]\n",
            "precision:  0.96\n",
            "recall:  0.96\n",
            "f1:  0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Apply another classification algorithm named kNN, which is an instance classifcation model. \n",
        "*  3.1. Perform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "\n",
        "*   3.2. Then compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "Rti2y0Wz2KY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "k_range = np.arange(1, 30, 2)\n",
        "data4 = datasets.load_iris()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data4.data, data4.target, test_size = 0.25)\n",
        "acls = []\n",
        "precision=[]\n",
        "recall = []\n",
        "f1 = []\n",
        "\n",
        "for k in k_range:\n",
        "  model = KNeighborsClassifier(n_neighbors=k)\n",
        "  model.fit(X_train, Y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  acls.append(y_pred)\n",
        "  precision.append(precision_score(Y_test, y_pred, average='micro'))\n",
        "  recall.append(recall_score(Y_test, y_pred, average='micro'))\n",
        "  f1.append(f1_score(Y_test, y_pred, average='micro'))\n",
        "\n",
        "print(f1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "13LkkfpS2ZUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed384974-ba5d-4292-8797-3b609c7fd605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9473684210526315]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Similar to Task 3, apply kNN algorithm to **mnist** dataset which included in datasets of sklearn API.\n",
        "*  4.1.\tPerform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "*  4.2.\tThen compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "k_range = np.arange(1, 30, 2)\n",
        "mnist = datasets.load_digits()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(mnist.data, mnist.target, test_size = 0.25)\n",
        "acls = []\n",
        "precision=[]\n",
        "recall = []\n",
        "f1 = []\n",
        "\n",
        "for k in k_range:\n",
        "  model = KNeighborsClassifier(n_neighbors=k)\n",
        "  model.fit(X_train, Y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  acls.append(y_pred)\n",
        "  precision.append(precision_score(Y_test, y_pred, average='micro'))\n",
        "  recall.append(recall_score(Y_test, y_pred, average='micro'))\n",
        "  f1.append(f1_score(Y_test, y_pred, average='micro'))\n",
        "\n",
        "print(f1)"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4969579-df1d-45ee-914e-b7fc73797f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9911111111111112, 0.9866666666666668, 0.9888888888888889, 0.9822222222222222, 0.9844444444444445, 0.9822222222222222, 0.9733333333333334, 0.9711111111111111, 0.9666666666666667, 0.9666666666666667, 0.9622222222222222, 0.9622222222222222, 0.9622222222222222, 0.9622222222222222, 0.96]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. \n",
        "Compare the performance of selected classification algorithms (**Decision Treen, kNN, and Logistic Regression**) to ***spam detection***. The dataset can be accessed from the link: http://archive.ics.uci.edu/ml/datasets/Spambase \n",
        "Attribute Information:\n",
        "The last column of 'spambase.csv denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes: \n",
        "*  48 continuous real [0,100] attributes of type word_freq_WORD \n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. **Example**: word_freq_address: percentage of words in the e-mail that match ADDRESS.\n",
        "*  6 continuous real [0,100] attributes of type char_freq_CHAR] \n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
        "*  1 continuous real [1,...] attribute of type capital_run_length_average \n",
        "= average length of uninterrupted sequences of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_longest \n",
        "= length of longest uninterrupted sequence of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
        "*  1 nominal {0,1} class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to compare the performance of selected algorithms, some common metrics including **accuracy, precision, recall, f1 measures** could be used.\n"
      ],
      "metadata": {
        "id": "MVzSk4l505E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "df = pd.read_csv(\"spambase.csv\")\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(mnist.data, mnist.target, test_size = 0.25)\n",
        "#Logistic Regression\n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(X_train, Y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"accuracy: \", accuracy_score(Y_test, y_pred))\n",
        "print(\"precision: \", precision_score(Y_test, y_pred, average='micro'))\n",
        "print(\"recall: \", recall_score(Y_test, y_pred, average='micro'))\n",
        "print(\"f1: \", f1_score(Y_test, y_pred, average='micro'))\n",
        "\n",
        "#kNN\n",
        "model = KNeighborsClassifier(n_neighbors=k)\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred2 = model.predict(X_test)\n",
        "print(\"\\nkNN\")\n",
        "print(\"accuracy: \", accuracy_score(Y_test, y_pred2))\n",
        "print(\"precision: \", precision_score(Y_test, y_pred2, average='micro'))\n",
        "print(\"recall: \", recall_score(Y_test, y_pred2, average='micro'))\n",
        "print(\"f1: \", f1_score(Y_test, y_pred2, average='micro'))\n",
        "\n",
        "#Decision Treen\n",
        "clf_model = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5)\n",
        "clf_model.fit(X_train, Y_train)\n",
        "# tree.plot_tree(clf)\n",
        "y_predict = clf_model.predict(X_test)\n",
        "print(\"\\nDecision Treen\")\n",
        "print(\"accuracy: \", accuracy_score(Y_test, y_predict))\n",
        "print(\"precision: \", precision_score(Y_test, y_predict, average='micro'))\n",
        "print(\"recall: \", recall_score(Y_test, y_predict, average='micro'))\n",
        "print(\"f1: \", f1_score(Y_test, y_predict, average='micro'))"
      ],
      "metadata": {
        "id": "W_1v_ivR2f6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f437d3-04ac-418a-e22f-e6c0e3145b32"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "accuracy:  0.9644444444444444\n",
            "precision:  0.9644444444444444\n",
            "recall:  0.9644444444444444\n",
            "f1:  0.9644444444444444\n",
            "\n",
            "kNN\n",
            "accuracy:  0.9555555555555556\n",
            "precision:  0.9555555555555556\n",
            "recall:  0.9555555555555556\n",
            "f1:  0.9555555555555556\n",
            "\n",
            "Decision Treen\n",
            "accuracy:  0.45555555555555555\n",
            "precision:  0.45555555555555555\n",
            "recall:  0.45555555555555555\n",
            "f1:  0.45555555555555555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}